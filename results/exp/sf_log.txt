[2025-11-26 15:58:20,991][66051] Saving configuration to ./results/exp/config.json...
[2025-11-26 15:58:20,999][66051] Rollout worker 0 uses device cpu
[2025-11-26 15:58:21,004][66051] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-11-26 15:58:21,004][66051] InferenceWorker_p0-w0: min num requests: 1
[2025-11-26 15:58:21,004][66051] Starting seed is not provided
[2025-11-26 15:58:21,005][66051] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-11-26 15:58:21,005][66051] Initializing actor-critic model on device cuda:0
[2025-11-26 15:58:21,062][66051] Created Actor Critic model with architecture:
[2025-11-26 15:58:21,062][66051] ActorCriticSharedWeights(
  (obs_normalizer): ObservationNormalizer()
  (encoder): MultiInputEncoder(
    (encoders): ModuleDict(
      (achieved_goal): MlpEncoder(
        (mlp_head): RecursiveScriptModule(
          original_name=Sequential
          (0): RecursiveScriptModule(original_name=Linear)
          (1): RecursiveScriptModule(original_name=Tanh)
          (2): RecursiveScriptModule(original_name=Linear)
          (3): RecursiveScriptModule(original_name=Tanh)
        )
      )
      (current_policy): MlpEncoder(
        (mlp_head): RecursiveScriptModule(
          original_name=Sequential
          (0): RecursiveScriptModule(original_name=Linear)
          (1): RecursiveScriptModule(original_name=Tanh)
          (2): RecursiveScriptModule(original_name=Linear)
          (3): RecursiveScriptModule(original_name=Tanh)
        )
      )
      (desired_goal): MlpEncoder(
        (mlp_head): RecursiveScriptModule(
          original_name=Sequential
          (0): RecursiveScriptModule(original_name=Linear)
          (1): RecursiveScriptModule(original_name=Tanh)
          (2): RecursiveScriptModule(original_name=Linear)
          (3): RecursiveScriptModule(original_name=Tanh)
        )
      )
      (observation): MlpEncoder(
        (mlp_head): RecursiveScriptModule(
          original_name=Sequential
          (0): RecursiveScriptModule(original_name=Linear)
          (1): RecursiveScriptModule(original_name=Tanh)
          (2): RecursiveScriptModule(original_name=Linear)
          (3): RecursiveScriptModule(original_name=Tanh)
        )
      )
      (rewards): MlpEncoder(
        (mlp_head): RecursiveScriptModule(
          original_name=Sequential
          (0): RecursiveScriptModule(original_name=Linear)
          (1): RecursiveScriptModule(original_name=Tanh)
          (2): RecursiveScriptModule(original_name=Linear)
          (3): RecursiveScriptModule(original_name=Tanh)
        )
      )
    )
  )
  (core): ModelCoreIdentity()
  (decoder): MlpDecoder(
    (mlp): Identity()
  )
  (critic_linear): Linear(in_features=320, out_features=1, bias=True)
  (action_parameterization): ActionParameterizationDefault(
    (distribution_linear): Linear(in_features=320, out_features=17, bias=True)
  )
)
[2025-11-26 15:58:21,183][66051] Using optimizer <class 'torch.optim.adam.Adam'>
[2025-11-26 15:58:21,784][66051] No checkpoints found
[2025-11-26 15:58:21,784][66051] Did not load from checkpoint, starting from scratch!
[2025-11-26 15:58:21,784][66051] Initialized policy 0 weights for model version 0
[2025-11-26 15:58:21,784][66051] LearnerWorker_p0 finished initialization!
[2025-11-26 15:58:21,785][66051] Using GPUs [0] for process 0 (actually maps to GPUs [0])
[2025-11-26 15:58:21,795][66051] Inference worker 0-0 is ready!
[2025-11-26 15:58:21,795][66051] All inference workers are ready! Signal rollout workers to start!
[2025-11-26 15:58:21,864][66051] Decorrelating experience for 0 frames...
[2025-11-26 15:58:21,931][66051] Decorrelating experience for 1024 frames...
[2025-11-26 15:58:24,645][66051] Fps is (10 sec: nan, 60 sec: nan, 300 sec: nan). Total num frames: 0. Throughput: 0: nan. Samples: 0. Policy #0 lag: (min: -1.0, avg: -1.0, max: -1.0)
[2025-11-26 15:58:24,645][66051] Avg episode reward: [(0, '-5.902')]
[2025-11-26 15:58:29,645][66051] Fps is (10 sec: 819.3, 60 sec: 819.3, 300 sec: 819.3). Total num frames: 4096. Throughput: 0: 820.1. Samples: 4100. Policy #0 lag: (min: 9.0, avg: 9.0, max: 9.0)
[2025-11-26 15:58:29,645][66051] Avg episode reward: [(0, '-6.424')]
[2025-11-26 15:58:35,450][66051] Fps is (10 sec: 758.2, 60 sec: 758.2, 300 sec: 758.2). Total num frames: 8192. Throughput: 0: 540.1. Samples: 5836. Policy #0 lag: (min: 9.0, avg: 9.0, max: 19.0)
[2025-11-26 15:58:35,451][66051] Avg episode reward: [(0, '-6.584')]
[2025-11-26 15:58:41,708][66051] Fps is (10 sec: 679.1, 60 sec: 720.2, 300 sec: 720.2). Total num frames: 12288. Throughput: 0: 566.8. Samples: 9672. Policy #0 lag: (min: 9.0, avg: 9.0, max: 19.0)
[2025-11-26 15:58:41,708][66051] Avg episode reward: [(0, '-6.592')]
[2025-11-26 15:58:41,713][66051] Heartbeat connected on Batcher_0
[2025-11-26 15:58:41,713][66051] Heartbeat connected on LearnerWorker_p0
[2025-11-26 15:58:41,714][66051] Heartbeat connected on InferenceWorker_p0-w0
[2025-11-26 15:58:41,714][66051] Heartbeat connected on RolloutWorker_w0
[2025-11-26 15:58:44,645][66051] Fps is (10 sec: 445.5, 60 sec: 614.4, 300 sec: 614.4). Total num frames: 12288. Throughput: 0: 673.9. Samples: 13478. Policy #0 lag: (min: 9.0, avg: 9.0, max: 19.0)
[2025-11-26 15:58:44,645][66051] Avg episode reward: [(0, '-6.308')]
[2025-11-26 15:58:49,644][66051] Fps is (10 sec: 516.1, 60 sec: 655.4, 300 sec: 655.4). Total num frames: 16384. Throughput: 0: 691.9. Samples: 17298. Policy #0 lag: (min: 1.0, avg: 1.0, max: 11.0)
[2025-11-26 15:58:49,644][66051] Avg episode reward: [(0, '-5.871')]
[2025-11-26 15:58:54,644][66051] Fps is (10 sec: 819.3, 60 sec: 682.7, 300 sec: 682.7). Total num frames: 20480. Throughput: 0: 682.8. Samples: 20484. Policy #0 lag: (min: 9.0, avg: 9.0, max: 19.0)
[2025-11-26 15:58:54,644][66051] Avg episode reward: [(0, '-5.677')]
[2025-11-26 15:58:58,977][66051] Early stopping after 4 epochs (4 sgd steps), loss delta 0.0000002
[2025-11-26 15:58:59,645][66051] Fps is (10 sec: 819.1, 60 sec: 702.2, 300 sec: 702.2). Total num frames: 24576. Throughput: 0: 696.7. Samples: 24384. Policy #0 lag: (min: 9.0, avg: 9.0, max: 19.0)
[2025-11-26 15:58:59,645][66051] Avg episode reward: [(0, '-5.461')]
[2025-11-26 15:59:04,951][66051] Fps is (10 sec: 794.8, 60 sec: 711.4, 300 sec: 711.4). Total num frames: 28672. Throughput: 0: 661.4. Samples: 26658. Policy #0 lag: (min: 2.0, avg: 2.0, max: 6.0)
[2025-11-26 15:59:04,952][66051] Avg episode reward: [(0, '-5.278')]
[2025-11-26 15:59:10,819][66051] Fps is (10 sec: 733.1, 60 sec: 709.7, 300 sec: 709.7). Total num frames: 32768. Throughput: 0: 666.3. Samples: 30768. Policy #0 lag: (min: 3.0, avg: 3.0, max: 13.0)
[2025-11-26 15:59:10,820][66051] Avg episode reward: [(0, '-5.368')]
[2025-11-26 15:59:12,586][66051] Keyboard interrupt detected in the event loop EvtLoop [Runner_EvtLoop, process=main process 66051], exiting...
[2025-11-26 15:59:12,587][66051] Runner profile tree view:
main_loop: 51.5823
[2025-11-26 15:59:12,587][66051] Collected {0: 32768}, FPS: 635.3
